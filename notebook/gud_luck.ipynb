{
 "cells": [
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:00.299747Z",
     "start_time": "2026-01-11T16:01:00.254569Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "697ba68f2aa0fe1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:00.947194Z",
     "start_time": "2026-01-11T16:01:00.936045Z"
    }
   },
   "source": [
    "DATASET_PATH = \"/Users/baptiste/cours/course_mlops/data/spam.csv\"\n",
    "\n",
    "# Tested multiple value 0.2 seems good\n",
    "TEST_SIZE = 0.2"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "758041dcab6bad3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:02.203841Z",
     "start_time": "2026-01-11T16:01:02.149142Z"
    }
   },
   "source": [
    "df = pd.read_csv(DATASET_PATH, encoding=\"ISO-8859-1\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "(5572, 5)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:03.127732Z",
     "start_time": "2026-01-11T16:01:03.108500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Label distribution :\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "print(\"Example of 'spam' message :\")\n",
    "print(df[df[\"label\"] == \"spam\"].head(2).values)\n",
    "\n",
    "print(\"Example of 'ham' message:\")\n",
    "print(df[df[\"label\"] == \"ham\"].head(2).values)"
   ],
   "id": "9ac1bd2102d6a891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution :\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "Example of 'spam' message :\n",
      "[['spam'\n",
      "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
      "  nan nan nan]\n",
      " ['spam'\n",
      "  \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, ï¿½1.50 to rcv\"\n",
      "  nan nan nan]]\n",
      "Example of 'ham' message:\n",
      "[['ham'\n",
      "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      "  nan nan nan]\n",
      " ['ham' 'Ok lar... Joking wif u oni...' nan nan nan]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:04.718242Z",
     "start_time": "2026-01-11T16:01:04.697116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##### Remove duplicates and null values #####\n",
    "\n",
    "print(f\"Before: {len(df)}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"message\"])\n",
    "\n",
    "print(f\"After: {len(df)}\")"
   ],
   "id": "3fbc5c7e4560bfba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 5572\n",
      "After: 5169\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "dc10f4ca30c525ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:06.192099Z",
     "start_time": "2026-01-11T16:01:06.068616Z"
    }
   },
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "df[\"message_clean\"] = df[\"message\"].str.lower()\n",
    "df[\"message_clean\"] = df[\"message_clean\"].apply(lambda x: re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", x))\n",
    "df[\"message_clean\"] = df[\"message_clean\"].apply(lambda x: re.sub(r\"\\S+@\\S+\", \"\", x))\n",
    "df[\"message_clean\"] = df[\"message_clean\"].apply(lambda x: re.sub(r\"\\d+\", \"\", x))\n",
    "df[\"message_clean\"] = df[\"message_clean\"].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "df[\"message_clean\"] = df[\"message_clean\"].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "print(f\"Before: {df['message'].iloc[0]}\")\n",
    "print(f\"After: {df['message_clean'].iloc[0]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "After: go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a472700633e90698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:07.375466Z",
     "start_time": "2026-01-11T16:01:07.339259Z"
    }
   },
   "source": [
    "df[\"message_length\"] = df[\"message\"].apply(len)\n",
    "df[\"word_count\"] = df[\"message\"].apply(lambda x: len(x.split()))\n",
    "df[\"avg_word_length\"] = df[\"message_length\"] / df[\"word_count\"]\n",
    "\n",
    "df[\"caps_count\"] = df[\"message\"].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "df[\"caps_ratio\"] = df[\"caps_count\"] / df[\"message_length\"]\n",
    "\n",
    "df[\"special_chars\"] = df[\"message\"].apply(lambda x: sum(1 for c in x if c in \"!?$€£%\"))\n",
    "\n",
    "print(\"features added :\")\n",
    "print(df[[\"message_length\", \"word_count\", \"caps_ratio\", \"special_chars\"]].describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features added :\n",
      "       message_length   word_count   caps_ratio  special_chars\n",
      "count      5169.00000  5169.000000  5169.000000    5169.000000\n",
      "mean         79.23196    15.340685     0.063230       0.533372\n",
      "std          58.33921    11.068488     0.110651       0.958554\n",
      "min           2.00000     1.000000     0.000000       0.000000\n",
      "25%          36.00000     7.000000     0.025000       0.000000\n",
      "50%          61.00000    12.000000     0.035971       0.000000\n",
      "75%         117.00000    22.000000     0.056250       1.000000\n",
      "max         910.00000   171.000000     1.000000      13.000000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "b31a749762d0e28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:08.595679Z",
     "start_time": "2026-01-11T16:01:08.048011Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tested multiple value 5000 is good\n",
    "# ngram with (1, 2) works\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.95, stop_words=\"english\")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(df[\"message_clean\"])\n",
    "print(f\"Shape TF-IDF: {X_tfidf.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape TF-IDF: (5169, 5000)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "afbc99702431c3dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:09.731469Z",
     "start_time": "2026-01-11T16:01:09.707934Z"
    }
   },
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "numerical_features = [\n",
    "    \"message_length\",\n",
    "    \"word_count\",\n",
    "    \"avg_word_length\",\n",
    "    \"caps_ratio\",\n",
    "    \"special_chars\",\n",
    "]\n",
    "\n",
    "X_numerical = df[numerical_features].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "X_numerical_sparse = csr_matrix(X_numerical_scaled)\n",
    "X_combined = hstack([X_tfidf, X_numerical_sparse])\n",
    "\n",
    "print(f\"Shape finale: {X_combined.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape finale: (5169, 5005)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:11.931921Z",
     "start_time": "2026-01-11T16:01:11.905304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"label\"])\n",
    "\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"Distribution: {np.bincount(y)}\")"
   ],
   "id": "9b4d7f6314e0d5ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ham' 'spam']\n",
      "Distribution: [4516  653]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:13.297075Z",
     "start_time": "2026-01-11T16:01:13.205109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=TEST_SIZE, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "import numpy as np\n",
    "\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"Classes :\", classes)"
   ],
   "id": "3f46bd31f9a13076",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4135, Test: 1034\n",
      "Classes : [0 1]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f4ea42194db2442a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:16.952135Z",
     "start_time": "2026-01-11T16:01:16.861423Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=le.classes_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.9574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       903\n",
      "        spam       0.91      0.73      0.81       131\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.94      0.86      0.89      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "17c431e0e9c84a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:36.130373Z",
     "start_time": "2026-01-11T16:01:33.292408Z"
    }
   },
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:01:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Accuracy: 0.9720\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98       903\n",
      "        spam       0.92      0.85      0.89       131\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.95      0.92      0.93      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "bf21074efa59e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:01:38.655632Z",
     "start_time": "2026-01-11T16:01:37.090357Z"
    }
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 0.5, 1.0, 5.0],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring=\"f1\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 5.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best CV score: 0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/baptiste/cours/course_mlops/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "ec639c3c96f963d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:31.689384Z",
     "start_time": "2026-01-11T16:02:31.661746Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "y_proba_final = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_final):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=le.classes_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9700\n",
      "ROC-AUC: 0.9899\n",
      "\n",
      "Confusion Matrix:\n",
      "[[898   5]\n",
      " [ 26 105]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       903\n",
      "        spam       0.95      0.80      0.87       131\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.96      0.90      0.93      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "54e9e21027317c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:32.417382Z",
     "start_time": "2026-01-11T16:02:32.359541Z"
    }
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_final)\n",
    "auc_score = roc_auc_score(y_test, y_proba_final)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_final)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"ROC Curve\", \"Precision-Recall Curve\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=fpr, y=tpr, name=f\"ROC (AUC = {auc_score:.3f})\", mode=\"lines\"),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=recall, y=precision, name=\"Precision-Recall\", mode=\"lines\"),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"True Positive Rate\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Recall\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Precision\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=500, width=1000, title_text=\"Model Evaluation Metrics\", showlegend=True)\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     26\u001B[39m fig.update_yaxes(title_text=\u001B[33m\"\u001B[39m\u001B[33mPrecision\u001B[39m\u001B[33m\"\u001B[39m, row=\u001B[32m1\u001B[39m, col=\u001B[32m2\u001B[39m)\n\u001B[32m     28\u001B[39m fig.update_layout(height=\u001B[32m500\u001B[39m, width=\u001B[32m1000\u001B[39m, title_text=\u001B[33m\"\u001B[39m\u001B[33mModel Evaluation Metrics\u001B[39m\u001B[33m\"\u001B[39m, showlegend=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[43mfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/cours/course_mlops/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:3420\u001B[39m, in \u001B[36mBaseFigure.show\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   3387\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3388\u001B[39m \u001B[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001B[39;00m\n\u001B[32m   3389\u001B[39m \u001B[33;03mspecified by the renderer argument\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   3416\u001B[39m \u001B[33;03mNone\u001B[39;00m\n\u001B[32m   3417\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3418\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplotly\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mio\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpio\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3420\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/cours/course_mlops/.venv/lib/python3.12/site-packages/plotly/io/_renderers.py:415\u001B[39m, in \u001B[36mshow\u001B[39m\u001B[34m(fig, renderer, validate, **kwargs)\u001B[39m\n\u001B[32m    410\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    411\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMime type rendering requires ipython but it is not installed\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    412\u001B[39m     )\n\u001B[32m    414\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nbformat \u001B[38;5;129;01mor\u001B[39;00m Version(nbformat.__version__) < Version(\u001B[33m\"\u001B[39m\u001B[33m4.2.0\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m415\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    416\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    417\u001B[39m     )\n\u001B[32m    419\u001B[39m display_jupyter_version_warnings()\n\u001B[32m    421\u001B[39m ipython_display.display(bundle, raw=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mValueError\u001B[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "972385349d225c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:34.814349Z",
     "start_time": "2026-01-11T16:02:34.774508Z"
    }
   },
   "source": [
    "feature_names = vectorizer.get_feature_names_out().tolist() + numerical_features\n",
    "\n",
    "coefs = best_model.coef_[0]\n",
    "top_positive = np.argsort(coefs)[-10:]\n",
    "top_negative = np.argsort(coefs)[:10]\n",
    "\n",
    "print(\"Top 10 features SPAM:\")\n",
    "for idx in reversed(top_positive):\n",
    "    print(f\"  {feature_names[idx]}: {coefs[idx]:.4f}\")\n",
    "\n",
    "print(\"Top 10 features HAM:\")\n",
    "for idx in top_negative:\n",
    "    print(f\"  {feature_names[idx]}: {coefs[idx]:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features SPAM:\n",
      "  txt: 6.3152\n",
      "  text: 5.5486\n",
      "  mobile: 4.8120\n",
      "  won: 4.6221\n",
      "  reply: 4.4612\n",
      "  claim: 4.3529\n",
      "  stop: 3.9335\n",
      "  new: 3.9217\n",
      "  prize: 3.9010\n",
      "  chat: 3.4649\n",
      "Top 10 features HAM:\n",
      "  ltgt: -7.0832\n",
      "  happy: -4.3668\n",
      "  word_count: -2.6398\n",
      "  amp: -2.3746\n",
      "  im: -2.3254\n",
      "  ½ï: -2.2796\n",
      "  ill: -2.2202\n",
      "  went: -1.8840\n",
      "  mail: -1.8190\n",
      "  day: -1.8123\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "f3e799bb7cb638be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:35.639668Z",
     "start_time": "2026-01-11T16:02:35.607816Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(\"models/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open(\"models/vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"models/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(\"models/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"OK\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "4cb06182f3554122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:37.203763Z",
     "start_time": "2026-01-11T16:02:37.168650Z"
    }
   },
   "source": [
    "def predict_spam(text: str) -> tuple[str, float]:\n",
    "    text_clean = text.lower()\n",
    "    text_clean = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text_clean)\n",
    "    text_clean = re.sub(r\"\\S+@\\S+\", \"\", text_clean)\n",
    "    text_clean = re.sub(r\"\\d+\", \"\", text_clean)\n",
    "    text_clean = text_clean.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text_clean = \" \".join(text_clean.split())\n",
    "\n",
    "    X_tfidf = vectorizer.transform([text_clean])\n",
    "\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split())\n",
    "    avg_word_length = text_length / word_count if word_count > 0 else 0\n",
    "    caps_count = sum(1 for c in text if c.isupper())\n",
    "    caps_ratio = caps_count / text_length if text_length > 0 else 0\n",
    "    special_chars = sum(1 for c in text if c in \"!?$€£%\")\n",
    "\n",
    "    X_numerical = [[text_length, word_count, avg_word_length, caps_ratio, special_chars]]\n",
    "    X_numerical_scaled = scaler.transform(X_numerical)\n",
    "\n",
    "    X_combined = hstack([X_tfidf, csr_matrix(X_numerical_scaled)])\n",
    "\n",
    "    pred = best_model.predict(X_combined)[0]\n",
    "    proba = best_model.predict_proba(X_combined)[0]\n",
    "\n",
    "    label = le.inverse_transform([pred])[0]\n",
    "    confidence = max(proba) * 100\n",
    "\n",
    "    return label, confidence\n",
    "\n",
    "\n",
    "test_messages = [\n",
    "    \"FREE!!! You have won a $1000 Walmart gift card! Click here to claim NOW!!!\",\n",
    "    \"Hey, are we still meeting for coffee tomorrow at 3pm?\",\n",
    "    \"URGENT: Your account will be suspended. Verify your details immediately.\",\n",
    "    \"Thanks for your help with the project yesterday. Really appreciated it!\",\n",
    "    \"Congratulations! You've been selected for a FREE iPhone 15! Call 0800-123-456\",\n",
    "    \"Can you send me the meeting notes when you get a chance?\",\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    label, confidence = predict_spam(msg)\n",
    "    emoji = \"🚫\" if label == \"spam\" else \"✅\"\n",
    "    print(f\"{emoji} [{label:4}] ({confidence:.1f}%) {msg[:50]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 [spam] (93.9%) FREE!!! You have won a $1000 Walmart gift card! Cl...\n",
      "✅ [ham ] (99.1%) Hey, are we still meeting for coffee tomorrow at 3...\n",
      "✅ [ham ] (66.6%) URGENT: Your account will be suspended. Verify you...\n",
      "✅ [ham ] (94.2%) Thanks for your help with the project yesterday. R...\n",
      "🚫 [spam] (59.5%) Congratulations! You've been selected for a FREE i...\n",
      "✅ [ham ] (96.7%) Can you send me the meeting notes when you get a c...\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "4b70e7350c8e870d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:02:38.557100Z",
     "start_time": "2026-01-11T16:02:38.547480Z"
    }
   },
   "source": [
    "# # Ancien code de preprocessing - ne pas utiliser\n",
    "# def old_preprocess(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^a-z\\s]', '', text)\n",
    "#     return text\n",
    "\n",
    "# # Essai avec SVM - trop lent, abandonné\n",
    "# from sklearn.svm import SVC\n",
    "# svm_model = SVC(kernel='rbf', probability=True)\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Test avec CountVectorizer au lieu de TF-IDF\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer(max_features=5000)\n",
    "# X_cv = cv.fit_transform(df['text_clean'])"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "197b0edb9dad53e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
